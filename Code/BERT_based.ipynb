{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId                             Phrase  Sentiment  \\\n",
      "0     18674         819                             paulin          2   \n",
      "1     15525         665                             tri go          2   \n",
      "2    119919        6413                          week live          2   \n",
      "3     17938         781                essenti collect bit          2   \n",
      "4     98852        5185  director fake backdrop state pace          1   \n",
      "\n",
      "   words_num  \n",
      "0          1  \n",
      "1          3  \n",
      "2          4  \n",
      "3          5  \n",
      "4         11  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load processed datasets\n",
    "train_data = pd.read_csv(\"../Dataset/train_preprocessed.csv\")\n",
    "val_data = pd.read_csv(\"../Dataset/val_preprocessed.csv\")\n",
    "test_data = pd.read_csv(\"../Dataset/test_preprocessed.csv\")\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_data(df):\n",
    "    return tokenizer(\n",
    "        df[\"Phrase\"].tolist(),  # Ensure we're tokenizing the \"Phrase\" column\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# set the Phrase column as str\n",
    "train_data[\"Phrase\"] = train_data[\"Phrase\"].astype(str)\n",
    "val_data[\"Phrase\"] = val_data[\"Phrase\"].astype(str)\n",
    "test_data[\"Phrase\"] = test_data[\"Phrase\"].astype(str)\n",
    "\n",
    "# Tokenize train, val, and test data\n",
    "train_encodings = tokenize_data(train_data)\n",
    "val_encodings = tokenize_data(val_data)\n",
    "test_encodings = tokenize_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}  # Tokenized input\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)  # Labels\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Sentiment labels to tensors\n",
    "train_labels = torch.tensor(train_data[\"Sentiment\"].values, dtype=torch.long)\n",
    "val_labels = torch.tensor(val_data[\"Sentiment\"].values, dtype=torch.long)\n",
    "test_labels = torch.tensor(test_data[\"Sentiment\"].values, dtype=torch.long)\n",
    "\n",
    "# Create datasets using the tokenized encodings and labels\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)\n",
    "test_dataset = SentimentDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move labels to GPU\n",
    "train_labels = train_labels.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "test_labels = test_labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=5,\n",
    "    hidden_dropout_prob=0.3,  # Increase dropout\n",
    "    attention_probs_dropout_prob=0.3,  # Dropout in attention layers\n",
    ")\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "Transformers version: 4.49.0\n",
      "Accelerate version: 0.28.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import accelerate\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Accelerate version:\", accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsj31\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"Model/\",\n",
    "    num_train_epochs=7,  # Increase epochs slightly\n",
    "    per_device_train_batch_size=8,  # Reduce batch size (helps generalization)\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"logs/\",\n",
    "    learning_rate=2e-5,  # Lower learning rate for better convergence\n",
    "    weight_decay=0.01,  # Add regularization\n",
    "    save_total_limit=2,  # Save only the last 2 models to save space\n",
    "    load_best_model_at_end=True,  # Load the best checkpoint\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    optimizers=(torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8), None),  # Custom optimizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained(\"Model/sentiment_bert_v2\") \n",
    "tokenizer.save_pretrained(\"Model/sentiment_bert_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsj31\\AppData\\Local\\Temp\\ipykernel_6060\\245516833.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)  # Labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1742' max='1742' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1742/1742 01:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5142714977264404, 'eval_model_preparation_time': 0.004, 'eval_runtime': 87.1804, 'eval_samples_per_second': 319.59, 'eval_steps_per_second': 19.982}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: 2\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {key: val.to(model.device) for key, val in inputs.items()}  # Move to GPU if available\n",
    "    outputs = model(**inputs)\n",
    "    prediction = outputs.logits.argmax().item()  # Get the predicted class\n",
    "    return prediction\n",
    "\n",
    "sentence = \"This movie was absolutely amazing!\"\n",
    "print(f\"Predicted Sentiment: {predict_sentiment(sentence)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
